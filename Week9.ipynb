{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d56309d7-b650-433a-9a20-d374d15e3c4c",
      "metadata": {
        "id": "d56309d7-b650-433a-9a20-d374d15e3c4c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0fc0802c-8447-44ca-b322-5db980a221b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0fc0802c-8447-44ca-b322-5db980a221b8",
        "outputId": "49d46357-a166-4a6d-8579-27bda22f8444"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.18.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "opAQA6jRRg0P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "opAQA6jRRg0P",
        "outputId": "15523ee6-4730-44f0-f1bc-22ef8587f295"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a886873e-4cd3-481b-aacb-7ffcbb3bd70c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a886873e-4cd3-481b-aacb-7ffcbb3bd70c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving shakespeare.txt to shakespeare.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2aa2c8c0-a56e-4c22-9438-5b656d6388e5",
      "metadata": {
        "id": "2aa2c8c0-a56e-4c22-9438-5b656d6388e5"
      },
      "outputs": [],
      "source": [
        "path_to_file = 'shakespeare.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7ea247aa-d2ca-4dd7-8c8f-88914fe7247d",
      "metadata": {
        "id": "7ea247aa-d2ca-4dd7-8c8f-88914fe7247d"
      },
      "outputs": [],
      "source": [
        "text = open(path_to_file, 'r').read()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1894d407-4490-4090-beb6-4a8271821366",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1894d407-4490-4090-beb6-4a8271821366",
        "outputId": "09d94729-34cc-4512-c768-4340544e73f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "844dcb26-3ce8-40d1-abf2-56fa40d038a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "844dcb26-3ce8-40d1-abf2-56fa40d038a3",
        "outputId": "bc9614d7-21d5-46bd-ca20-57c80b5259bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '}']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "vocab = sorted(set(text))\n",
        "print(vocab)\n",
        "len(vocab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "55a7ed4b-e941-46bf-ba6c-e95ba52fddab",
      "metadata": {
        "id": "55a7ed4b-e941-46bf-ba6c-e95ba52fddab"
      },
      "outputs": [],
      "source": [
        "char_to_ind = {u:i for i, u in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2b126132-b779-4844-baec-718c02c0382f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b126132-b779-4844-baec-718c02c0382f",
        "outputId": "cdb9b270-04e8-4364-9fa7-ed794a93c1f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " '`': 55,\n",
              " 'a': 56,\n",
              " 'b': 57,\n",
              " 'c': 58,\n",
              " 'd': 59,\n",
              " 'e': 60,\n",
              " 'f': 61,\n",
              " 'g': 62,\n",
              " 'h': 63,\n",
              " 'i': 64,\n",
              " 'j': 65,\n",
              " 'k': 66,\n",
              " 'l': 67,\n",
              " 'm': 68,\n",
              " 'n': 69,\n",
              " 'o': 70,\n",
              " 'p': 71,\n",
              " 'q': 72,\n",
              " 'r': 73,\n",
              " 's': 74,\n",
              " 't': 75,\n",
              " 'u': 76,\n",
              " 'v': 77,\n",
              " 'w': 78,\n",
              " 'x': 79,\n",
              " 'y': 80,\n",
              " 'z': 81,\n",
              " '|': 82,\n",
              " '}': 83}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "char_to_ind\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "53fabb89-2cc6-4910-afa5-a371580e29d6",
      "metadata": {
        "id": "53fabb89-2cc6-4910-afa5-a371580e29d6"
      },
      "outputs": [],
      "source": [
        "ind_to_char = np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7c56f298-7431-4349-baa4-e75e58163fc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c56f298-7431-4349-baa4-e75e58163fc7",
        "outputId": "9ffb4535-dc67-40e7-a44c-9e3ad4948a8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n",
              "       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
              "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
              "       'w', 'x', 'y', 'z', '|', '}'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "ind_to_char\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a0ca5923-88a5-4bc8-854a-991205eb9dc8",
      "metadata": {
        "id": "a0ca5923-88a5-4bc8-854a-991205eb9dc8"
      },
      "outputs": [],
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "eef33582-d009-4f44-bcad-70cc15be2087",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eef33582-d009-4f44-bcad-70cc15be2087",
        "outputId": "33d3a3ab-7fa8-43a6-bc00-d2399d35faae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1, ..., 30, 39, 29])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "encoded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0aa8a2e3-46fc-4cb7-88ad-e03d73a909f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0aa8a2e3-46fc-4cb7-88ad-e03d73a909f9",
        "outputId": "b73b4d1b-98fd-45aa-c3ad-9e3a10d884fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n                   '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "sample = text[:20]\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e1274eaf-c9ec-45d5-9684-bc6079cc7a33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1274eaf-c9ec-45d5-9684-bc6079cc7a33",
        "outputId": "fad2fe4b-7bbe-4233-f72a-924ef4673659"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "encoded_text[:20]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d3e96cdb-213f-496f-9b27-d69329b056b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3e96cdb-213f-496f-9b27-d69329b056b2",
        "outputId": "906c01e4-1347-4f6c-fbb9-7814d5d89fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6b8fd7ae-93c1-4ad5-af3c-9a0e1915bd4a",
      "metadata": {
        "id": "6b8fd7ae-93c1-4ad5-af3c-9a0e1915bd4a"
      },
      "outputs": [],
      "source": [
        "line = \"From fairest creatures we desire increase\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fca2880f-f3cf-47d0-bac8-65088ec3c972",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fca2880f-f3cf-47d0-bac8-65088ec3c972",
        "outputId": "95881f77-a79e-4763-d866-02ddc1d880e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "470f1999-35e0-4d3e-91a1-253f75da7cf3",
      "metadata": {
        "id": "470f1999-35e0-4d3e-91a1-253f75da7cf3"
      },
      "outputs": [],
      "source": [
        "part_stanza = \"\"\"From fairest creatures we desire increase,\n",
        "That thereby beauty's rose might never die,\n",
        "But as the riper should by time decease,\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6c6a09e1-1a64-4113-9c5e-e5b311a56699",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c6a09e1-1a64-4113-9c5e-e5b311a56699",
        "outputId": "50449694-999e-4764-c86b-035c83b2f79f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(part_stanza)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ad189c44-8715-4ec3-b975-a6dbd0a78fd9",
      "metadata": {
        "id": "ad189c44-8715-4ec3-b975-a6dbd0a78fd9"
      },
      "outputs": [],
      "source": [
        "seq_len = 120\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6f68424c-12c2-479c-81d1-6e85a3c574ac",
      "metadata": {
        "id": "6f68424c-12c2-479c-81d1-6e85a3c574ac"
      },
      "outputs": [],
      "source": [
        "total_num_seq = len(text)//(seq_len+1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5bc8849f-44f7-43af-945e-0496ee449593",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bc8849f-44f7-43af-945e-0496ee449593",
        "outputId": "997244ac-cfea-4926-fb7b-4f4bfd1842b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "total_num_seq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "299ec4ad-8f0b-446a-a769-bd65b7cc3823",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "299ec4ad-8f0b-446a-a769-bd65b7cc3823",
        "outputId": "03b2f999-bb9c-40cd-891b-5fd03c41a824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "1\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "r\n",
            "o\n",
            "m\n",
            " \n",
            "f\n",
            "a\n",
            "i\n",
            "r\n",
            "e\n",
            "s\n",
            "t\n",
            " \n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "t\n",
            "u\n",
            "r\n",
            "e\n",
            "s\n",
            " \n",
            "w\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "s\n",
            "i\n",
            "r\n",
            "e\n",
            " \n",
            "i\n",
            "n\n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            "b\n",
            "y\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "u\n",
            "t\n",
            "y\n",
            "'\n",
            "s\n",
            " \n",
            "r\n",
            "o\n",
            "s\n",
            "e\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "n\n",
            "e\n",
            "v\n",
            "e\n",
            "r\n",
            " \n",
            "d\n",
            "i\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "r\n",
            "i\n",
            "p\n",
            "e\n",
            "r\n",
            " \n",
            "s\n",
            "h\n",
            "o\n",
            "u\n",
            "l\n",
            "d\n",
            " \n",
            "b\n",
            "y\n",
            " \n",
            "t\n",
            "i\n",
            "m\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "c\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "H\n",
            "i\n",
            "s\n",
            " \n",
            "t\n",
            "e\n",
            "n\n",
            "d\n",
            "e\n",
            "r\n",
            " \n",
            "h\n",
            "e\n",
            "i\n",
            "r\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "r\n",
            " \n",
            "h\n",
            "i\n",
            "s\n",
            " \n",
            "m\n",
            "e\n",
            "m\n",
            "o\n",
            "r\n",
            "y\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "c\n",
            "o\n",
            "n\n",
            "t\n",
            "r\n",
            "a\n",
            "c\n",
            "t\n",
            "e\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "r\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "e\n",
            "y\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "e\n",
            "e\n",
            "d\n",
            "'\n",
            "s\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "l\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "l\n",
            "a\n",
            "m\n",
            "e\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            "-\n",
            "s\n",
            "u\n",
            "b\n",
            "s\n",
            "t\n",
            "a\n",
            "n\n",
            "t\n",
            "i\n",
            "a\n",
            "l\n",
            " \n",
            "f\n",
            "u\n",
            "e\n",
            "l\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "M\n",
            "a\n",
            "k\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "a\n",
            " \n",
            "f\n",
            "a\n",
            "m\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "w\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "b\n",
            "u\n",
            "n\n",
            "d\n",
            "a\n",
            "n\n",
            "c\n",
            "e\n",
            " \n",
            "l\n",
            "i\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "f\n",
            "o\n",
            "e\n",
            ",\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "w\n",
            "e\n",
            "e\n",
            "t\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "o\n",
            "o\n",
            " \n",
            "c\n",
            "r\n",
            "u\n",
            "e\n",
            "l\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "t\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "a\n",
            "r\n",
            "t\n",
            " \n",
            "n\n",
            "o\n",
            "w\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "o\n",
            "r\n",
            "l\n",
            "d\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "r\n",
            "e\n",
            "s\n",
            "h\n",
            " \n",
            "o\n",
            "r\n",
            "n\n",
            "a\n",
            "m\n",
            "e\n",
            "n\n",
            "t\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "A\n",
            "n\n",
            "d\n",
            " \n",
            "o\n",
            "n\n",
            "l\n",
            "y\n",
            " \n",
            "h\n",
            "e\n",
            "r\n",
            "a\n",
            "l\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "g\n",
            "a\n",
            "u\n",
            "d\n",
            "y\n",
            " \n",
            "s\n",
            "p\n",
            "r\n",
            "i\n",
            "n\n",
            "g\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "W\n",
            "i\n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "u\n"
          ]
        }
      ],
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
        "for i in char_dataset.take(500):\n",
        " print(ind_to_char[i.numpy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c193bfa4-0901-42fb-b725-673f8d06d79a",
      "metadata": {
        "id": "c193bfa4-0901-42fb-b725-673f8d06d79a"
      },
      "outputs": [],
      "source": [
        "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "c711cee0-e044-4141-83df-813e3fcb09c9",
      "metadata": {
        "id": "c711cee0-e044-4141-83df-813e3fcb09c9"
      },
      "outputs": [],
      "source": [
        "def create_seq_targets(seq):\n",
        " input_txt = seq[:-1]\n",
        " target_txt = seq[1:]\n",
        " return input_txt, target_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "70e3b465-870d-4219-8631-32cd49974ad3",
      "metadata": {
        "id": "70e3b465-870d-4219-8631-32cd49974ad3"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(create_seq_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5f03de9a-886c-4d4e-82db-3609a2a678f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f03de9a-886c-4d4e-82db-3609a2a678f1",
        "outputId": "0e3cf827-2850-461f-f58c-2ef8161da260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ]
        }
      ],
      "source": [
        "for input_txt, target_txt in dataset.take(1):\n",
        " print(input_txt.numpy())\n",
        " print(''.join(ind_to_char[input_txt.numpy()]))\n",
        " print('\\n')\n",
        " print(target_txt.numpy())\n",
        " # There is an extra whitespace!\n",
        " print(''.join(ind_to_char[target_txt.numpy()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1fa7298f-ce87-42b1-bd4b-85fe89916aaa",
      "metadata": {
        "id": "1fa7298f-ce87-42b1-bd4b-85fe89916aaa"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "buffer_size=10000\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "951c2e9b-b963-4e60-8a6c-1622ee58e003",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "951c2e9b-b963-4e60-8a6c-1622ee58e003",
        "outputId": "8bd344b9-342f-4b54-83f6-aabcdf92af5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int64, name=None), TensorSpec(shape=(128, 120), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "01a01810-3ea1-4ad3-8682-e98bb2bad784",
      "metadata": {
        "id": "01a01810-3ea1-4ad3-8682-e98bb2bad784"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)\n",
        "# The embedding dimension\n",
        "embed_dim = 64\n",
        "# Number of RNN units\n",
        "rnn_neurons = 1026"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "35155e37-d69a-4b2b-ba6a-f1d7c462e13d",
      "metadata": {
        "id": "35155e37-d69a-4b2b-ba6a-f1d7c462e13d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "da7c0811-a81e-46ab-a75b-d8fffdaccacf",
      "metadata": {
        "id": "da7c0811-a81e-46ab-a75b-d8fffdaccacf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "012bb546-c024-485f-adc9-1d960bfaa3db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "012bb546-c024-485f-adc9-1d960bfaa3db",
        "outputId": "fba1f59f-b7f7-4120-a057-5dc096db10ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function sparse_categorical_crossentropy in module keras.src.losses.losses:\n",
            "\n",
            "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, ignore_class=None, axis=-1)\n",
            "    Computes the sparse categorical crossentropy loss.\n",
            "    \n",
            "    Args:\n",
            "        y_true: Ground truth values.\n",
            "        y_pred: The predicted values.\n",
            "        from_logits: Whether `y_pred` is expected to be a logits tensor. By\n",
            "            default, we assume that `y_pred` encodes a probability distribution.\n",
            "        ignore_class: Optional integer. The ID of a class to be ignored during\n",
            "            loss computation. This is useful, for example, in segmentation\n",
            "            problems featuring a \"void\" class (commonly -1 or 255) in\n",
            "            segmentation maps. By default (`ignore_class=None`), all classes are\n",
            "            considered.\n",
            "        axis: Defaults to `-1`. The dimension along which the entropy is\n",
            "            computed.\n",
            "    \n",
            "    Returns:\n",
            "        Sparse categorical crossentropy loss value.\n",
            "    \n",
            "    Examples:\n",
            "    \n",
            "    >>> y_true = [1, 2]\n",
            "    >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
            "    >>> loss = keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
            "    >>> assert loss.shape == (2,)\n",
            "    >>> loss\n",
            "    array([0.0513, 2.303], dtype=float32)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(sparse_categorical_crossentropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "592b28f5-214c-4199-b31f-d926c3cf0d68",
      "metadata": {
        "id": "592b28f5-214c-4199-b31f-d926c3cf0d68"
      },
      "outputs": [],
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "744d1642-c304-479d-bf83-b4a937f9614b",
      "metadata": {
        "id": "744d1642-c304-479d-bf83-b4a937f9614b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "298da4c9-a809-4677-96df-d7aece1cb43a",
      "metadata": {
        "id": "298da4c9-a809-4677-96df-d7aece1cb43a"
      },
      "outputs": [],
      "source": [
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embed_dim, input_shape=(None,)))  # Updated\n",
        "    model.add(GRU(rnn_neurons, return_sequences=True, stateful=False, recurrent_initializer='glorot_uniform'))\n",
        "    model.add(Dense(vocab_size))  # Final Dense Layer to Predict\n",
        "\n",
        "    model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(from_logits=True))\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a18beac4-dcfb-4efc-b255-880e5ace610d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a18beac4-dcfb-4efc-b255-880e5ace610d",
        "outputId": "76dfae34-7718-4435-ee11-39c70f55f30d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = create_model(\n",
        "vocab_size = vocab_size,\n",
        "embed_dim = embed_dim,\n",
        "rnn_neurons = rnn_neurons,\n",
        "batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "4f267529-b869-49ba-b966-b98652ddb6a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "4f267529-b869-49ba-b966-b98652ddb6a9",
        "outputId": "1752964d-7f78-41df-b3e7-7cd82ffbd542"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m5,376\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1026\u001b[0m)          │       \u001b[38;5;34m3,361,176\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)            │          \u001b[38;5;34m86,268\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1026</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,361,176</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">86,268</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,452,820\u001b[0m (13.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,452,820</span> (13.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,452,820\u001b[0m (13.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,452,820</span> (13.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "1b359d55-54c3-4ca8-98bd-24bf54c0d96d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b359d55-54c3-4ca8-98bd-24bf54c0d96d",
        "outputId": "d0533dfa-7de5-4997-c14b-2f339969827d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 120, 84) <=== (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    # Predict off some random batch\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "\n",
        "    # Display the dimensions of the predictions\n",
        "    print(example_batch_predictions.shape, \"<=== (batch_size, sequence_length, vocab_size)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "93228817-0480-4774-b3af-0badee98ee72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93228817-0480-4774-b3af-0badee98ee72",
        "outputId": "653df0a5-b003-4242-df14-1ed50287af98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 120, 84), dtype=float32, numpy=\n",
              "array([[[ 7.8316493e-04, -6.0076276e-03, -1.7689103e-03, ...,\n",
              "          2.1383252e-03,  6.3471124e-03,  4.6732444e-03],\n",
              "        [-3.4451575e-03,  6.8178104e-04,  2.8403447e-04, ...,\n",
              "          7.4997935e-03,  6.9312175e-04,  7.3164860e-03],\n",
              "        [-4.2277211e-03, -5.3846473e-03,  6.0079680e-03, ...,\n",
              "          4.3653706e-03,  6.8466100e-03,  7.7362679e-04],\n",
              "        ...,\n",
              "        [-4.5768754e-04,  1.3946312e-03, -2.9546604e-03, ...,\n",
              "         -1.4173625e-03,  1.2784912e-03,  2.3549278e-03],\n",
              "        [-2.0542012e-03, -4.0171137e-03, -2.5152704e-03, ...,\n",
              "          2.5818381e-03, -5.2026208e-03, -2.8603107e-03],\n",
              "        [-4.3702228e-03, -7.2010709e-03,  2.8442990e-03, ...,\n",
              "          2.4574208e-03,  1.7714219e-03, -3.8220030e-03]],\n",
              "\n",
              "       [[-4.7397008e-03,  2.6570358e-03, -6.1786203e-03, ...,\n",
              "          1.8401560e-03,  3.9999001e-03,  2.8044425e-03],\n",
              "        [-1.5854019e-03, -4.5808665e-03, -5.1417146e-03, ...,\n",
              "          4.3711308e-03,  7.4593285e-03,  6.0679191e-03],\n",
              "        [ 6.3289520e-03, -3.0677647e-03, -2.7567169e-03, ...,\n",
              "         -1.1707889e-03,  4.6214828e-04,  5.9407926e-03],\n",
              "        ...,\n",
              "        [-5.6769173e-03, -3.4145964e-03, -4.0850234e-03, ...,\n",
              "          8.1490409e-03,  6.2508052e-03,  4.5053768e-03],\n",
              "        [-7.1111233e-03, -7.0688706e-03,  3.9534243e-03, ...,\n",
              "          5.8349371e-03,  8.7331170e-03, -6.1202532e-04],\n",
              "        [-5.6016510e-03, -1.7537336e-03,  3.7010505e-03, ...,\n",
              "          4.1232225e-03,  6.3147079e-03, -2.1691192e-03]],\n",
              "\n",
              "       [[-3.3100205e-03,  5.4825186e-03, -5.6005768e-03, ...,\n",
              "         -1.0294619e-03,  7.6741875e-05, -2.4716808e-03],\n",
              "        [ 6.6963686e-03, -6.8138615e-04, -4.3726419e-03, ...,\n",
              "         -4.7629233e-03,  4.4921706e-03,  2.8606893e-03],\n",
              "        [-2.1809108e-04, -6.1027571e-03,  3.0564885e-03, ...,\n",
              "         -1.8221952e-03,  7.4891439e-03, -1.2776074e-03],\n",
              "        ...,\n",
              "        [-2.8787734e-04,  4.9375598e-03,  8.4206359e-03, ...,\n",
              "         -4.8673968e-03,  4.9150377e-03,  5.1926947e-03],\n",
              "        [ 1.5189474e-03,  7.6185660e-03,  9.7645872e-04, ...,\n",
              "         -4.6218424e-03, -8.7448396e-03,  2.0675480e-03],\n",
              "        [-2.3875970e-03, -2.0522812e-04,  1.0239254e-03, ...,\n",
              "          2.2701563e-03, -9.5100366e-03, -1.5389823e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-3.3100205e-03,  5.4825186e-03, -5.6005768e-03, ...,\n",
              "         -1.0294619e-03,  7.6741875e-05, -2.4716808e-03],\n",
              "        [-3.4712818e-03,  8.4131965e-03, -3.8259258e-03, ...,\n",
              "          2.9394871e-03, -2.1515943e-03,  4.0662903e-03],\n",
              "        [ 1.9001793e-03,  1.0336855e-03, -7.8014960e-03, ...,\n",
              "          4.3313042e-03, -1.2700808e-03, -1.1675879e-03],\n",
              "        ...,\n",
              "        [-1.1792178e-03, -6.1518387e-03,  2.6145286e-04, ...,\n",
              "         -1.8143079e-03, -7.1274363e-03, -2.9420925e-03],\n",
              "        [-6.7001665e-03, -9.8462561e-03,  7.2718790e-04, ...,\n",
              "         -2.0739504e-03, -5.4012174e-03, -2.3264147e-03],\n",
              "        [-4.0187822e-03, -6.9979015e-03,  1.4578493e-03, ...,\n",
              "          1.0086854e-03, -1.0138870e-02, -3.8993938e-03]],\n",
              "\n",
              "       [[-2.9787298e-03,  4.6187798e-03,  8.3586393e-04, ...,\n",
              "          6.1733047e-03, -3.1498102e-03,  4.6789711e-03],\n",
              "        [-3.5309016e-03, -2.9187610e-03,  6.2010186e-03, ...,\n",
              "          3.4542426e-03,  4.4696433e-03, -7.1371306e-04],\n",
              "        [-5.2264966e-03, -4.8253890e-03,  9.2640659e-03, ...,\n",
              "          2.8331724e-03,  7.0403195e-03, -4.0201717e-03],\n",
              "        ...,\n",
              "        [-2.7930639e-03,  2.8453500e-03,  2.0038523e-03, ...,\n",
              "          2.6391682e-03,  2.0670183e-03,  1.1254784e-03],\n",
              "        [-6.0711741e-03, -9.4338605e-04,  8.1852395e-03, ...,\n",
              "          6.0498747e-03,  6.9495831e-03,  4.9548788e-04],\n",
              "        [-9.5412359e-03,  1.9664401e-03, -2.5829049e-03, ...,\n",
              "          6.3423100e-03,  6.9529493e-03,  1.9658296e-03]],\n",
              "\n",
              "       [[-2.4241058e-03, -4.5635966e-03, -4.8603601e-04, ...,\n",
              "          3.9223377e-03, -5.3822231e-03, -3.1849253e-03],\n",
              "        [-6.5894937e-03, -3.9921558e-04, -7.8462819e-03, ...,\n",
              "          4.7232793e-03,  5.6350324e-04,  2.1943280e-03],\n",
              "        [-6.9172084e-03, -4.7852183e-03,  7.2358502e-04, ...,\n",
              "          4.9208212e-03,  4.4699349e-03, -1.2365089e-03],\n",
              "        ...,\n",
              "        [-6.8226946e-03,  1.9647177e-04,  4.8019728e-03, ...,\n",
              "         -5.0525891e-04,  1.7865701e-03, -5.1343553e-03],\n",
              "        [-3.4603528e-03, -3.8997924e-03,  1.0539563e-03, ...,\n",
              "          2.5582144e-03,  6.2406594e-03,  9.1534440e-04],\n",
              "        [-3.5393909e-03, -9.4616163e-04,  2.4306129e-03, ...,\n",
              "          1.6333060e-03,  5.6161480e-03, -1.1652309e-03]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "example_batch_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "e8c4b68c-b5ff-4649-816b-4cfcb9792be3",
      "metadata": {
        "id": "e8c4b68c-b5ff-4649-816b-4cfcb9792be3"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "64d2fd4e-2cc2-4fbb-bcc7-537b88c37881",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64d2fd4e-2cc2-4fbb-bcc7-537b88c37881",
        "outputId": "cd494122-bfd5-4dd0-9e19-02a2a6422b76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
              "array([[13],\n",
              "       [ 7],\n",
              "       [72],\n",
              "       [42],\n",
              "       [63],\n",
              "       [41],\n",
              "       [ 5],\n",
              "       [48],\n",
              "       [28],\n",
              "       [59],\n",
              "       [80],\n",
              "       [32],\n",
              "       [74],\n",
              "       [69],\n",
              "       [69],\n",
              "       [36],\n",
              "       [28],\n",
              "       [77],\n",
              "       [53],\n",
              "       [78],\n",
              "       [30],\n",
              "       [33],\n",
              "       [35],\n",
              "       [ 3],\n",
              "       [61],\n",
              "       [23],\n",
              "       [21],\n",
              "       [10],\n",
              "       [43],\n",
              "       [ 5],\n",
              "       [14],\n",
              "       [46],\n",
              "       [38],\n",
              "       [79],\n",
              "       [69],\n",
              "       [24],\n",
              "       [32],\n",
              "       [67],\n",
              "       [25],\n",
              "       [80],\n",
              "       [31],\n",
              "       [28],\n",
              "       [50],\n",
              "       [61],\n",
              "       [66],\n",
              "       [36],\n",
              "       [74],\n",
              "       [48],\n",
              "       [25],\n",
              "       [41],\n",
              "       [62],\n",
              "       [22],\n",
              "       [ 9],\n",
              "       [24],\n",
              "       [62],\n",
              "       [39],\n",
              "       [80],\n",
              "       [40],\n",
              "       [36],\n",
              "       [58],\n",
              "       [80],\n",
              "       [21],\n",
              "       [56],\n",
              "       [15],\n",
              "       [33],\n",
              "       [23],\n",
              "       [82],\n",
              "       [63],\n",
              "       [77],\n",
              "       [ 7],\n",
              "       [37],\n",
              "       [48],\n",
              "       [65],\n",
              "       [15],\n",
              "       [28],\n",
              "       [74],\n",
              "       [56],\n",
              "       [ 5],\n",
              "       [32],\n",
              "       [30],\n",
              "       [27],\n",
              "       [64],\n",
              "       [15],\n",
              "       [12],\n",
              "       [34],\n",
              "       [ 9],\n",
              "       [17],\n",
              "       [52],\n",
              "       [74],\n",
              "       [15],\n",
              "       [14],\n",
              "       [37],\n",
              "       [ 8],\n",
              "       [71],\n",
              "       [75],\n",
              "       [40],\n",
              "       [64],\n",
              "       [42],\n",
              "       [ 6],\n",
              "       [51],\n",
              "       [25],\n",
              "       [54],\n",
              "       [75],\n",
              "       [46],\n",
              "       [78],\n",
              "       [51],\n",
              "       [51],\n",
              "       [81],\n",
              "       [24],\n",
              "       [51],\n",
              "       [28],\n",
              "       [ 8],\n",
              "       [83],\n",
              "       [55],\n",
              "       [59],\n",
              "       [ 5],\n",
              "       [31],\n",
              "       [ 0],\n",
              "       [73],\n",
              "       [11]])>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "sampled_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "7aa1139e-7b0b-4dd1-b5fe-fc81ed919434",
      "metadata": {
        "id": "7aa1139e-7b0b-4dd1-b5fe-fc81ed919434"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "85af1245-9cfa-4006-9afb-716d4a312b44",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85af1245-9cfa-4006-9afb-716d4a312b44",
        "outputId": "620e8782-77ca-404e-ba1d-b0600dc310b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13,  7, 72, 42, 63, 41,  5, 48, 28, 59, 80, 32, 74, 69, 69, 36, 28,\n",
              "       77, 53, 78, 30, 33, 35,  3, 61, 23, 21, 10, 43,  5, 14, 46, 38, 79,\n",
              "       69, 24, 32, 67, 25, 80, 31, 28, 50, 61, 66, 36, 74, 48, 25, 41, 62,\n",
              "       22,  9, 24, 62, 39, 80, 40, 36, 58, 80, 21, 56, 15, 33, 23, 82, 63,\n",
              "       77,  7, 37, 48, 65, 15, 28, 74, 56,  5, 32, 30, 27, 64, 15, 12, 34,\n",
              "        9, 17, 52, 74, 15, 14, 37,  8, 71, 75, 40, 64, 42,  6, 51, 25, 54,\n",
              "       75, 46, 78, 51, 51, 81, 24, 51, 28,  8, 83, 55, 59,  5, 31,  0, 73,\n",
              "       11])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "fe98040c-b68e-4b0c-911e-415bb938f96f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe98040c-b68e-4b0c-911e-415bb938f96f",
        "outputId": "87da9744-13b7-407e-f8f0-dc7bcc17205f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given the input seq: \n",
            "\n",
            "t\n",
            "    not honesty to have it thus set down; for you yourself, sir,\n",
            "    should be old as I am if, like a crab, you could \n",
            "\n",
            "\n",
            "Next Char Predictions: \n",
            "\n",
            "2)qQhP'WCdyGsnnKCv]wEHJ\"f<:.R'3UMxn>Gl?yFCYfkKsW?Pg;->gNyOKcy:a4H<|hv)LWj4Csa'GEBi41I-6[s43L,ptOiQ(Z?_tUwZZz>ZC,}`d'F\n",
            "r0\n"
          ]
        }
      ],
      "source": [
        "print(\"Given the input seq: \\n\")\n",
        "print(\"\".join(ind_to_char[input_example_batch[0]]))\n",
        "print('\\n')\n",
        "print(\"Next Char Predictions: \\n\")\n",
        "print(\"\".join(ind_to_char[sampled_indices ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "f45fb1d8-77dc-4fee-abc6-991439425cd1",
      "metadata": {
        "id": "f45fb1d8-77dc-4fee-abc6-991439425cd1"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c3fe0a3-d58e-4473-8f10-299279ef9985",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c3fe0a3-d58e-4473-8f10-299279ef9985",
        "outputId": "7e6c8f3c-ca7d-463b-a127-bc04c8dfacbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 134ms/step - loss: 2.8827\n",
            "Epoch 2/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 141ms/step - loss: 1.6128\n",
            "Epoch 3/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 139ms/step - loss: 1.3715\n",
            "Epoch 4/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 1.2729\n",
            "Epoch 5/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 1.2159\n",
            "Epoch 6/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 140ms/step - loss: 1.1783\n",
            "Epoch 7/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 1.1488\n",
            "Epoch 8/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 1.1239\n",
            "Epoch 9/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 142ms/step - loss: 1.1032\n",
            "Epoch 10/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 138ms/step - loss: 1.0847\n",
            "Epoch 11/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 141ms/step - loss: 1.0677\n",
            "Epoch 12/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 1.0520\n",
            "Epoch 13/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 1.0347\n",
            "Epoch 14/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 143ms/step - loss: 1.0200\n",
            "Epoch 15/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 138ms/step - loss: 1.0073\n",
            "Epoch 16/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 0.9924\n",
            "Epoch 17/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 142ms/step - loss: 0.9815\n",
            "Epoch 18/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 138ms/step - loss: 0.9683\n",
            "Epoch 19/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 141ms/step - loss: 0.9577\n",
            "Epoch 20/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 0.9465\n",
            "Epoch 21/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 143ms/step - loss: 0.9358\n",
            "Epoch 22/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 138ms/step - loss: 0.9286\n",
            "Epoch 23/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 141ms/step - loss: 0.9208\n",
            "Epoch 24/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 139ms/step - loss: 0.9122\n",
            "Epoch 25/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 143ms/step - loss: 0.9059\n",
            "Epoch 26/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 141ms/step - loss: 0.9014\n",
            "Epoch 27/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 142ms/step - loss: 0.8966\n",
            "Epoch 28/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 138ms/step - loss: 0.8918\n",
            "Epoch 29/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 141ms/step - loss: 0.8896\n",
            "Epoch 30/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 142ms/step - loss: 0.8865\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x780cb9ace2d0>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(dataset,epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "78a75c9f-b6b6-46b1-9063-1e993b19a345",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78a75c9f-b6b6-46b1-9063-1e993b19a345",
        "outputId": "618c88a2-8476-48cb-b2b1-217255ee353c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('shakespeare_gen.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "mkrNpdGSa_4I",
      "metadata": {
        "id": "mkrNpdGSa_4I"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "cknvpiXTbIud",
      "metadata": {
        "id": "cknvpiXTbIud"
      },
      "outputs": [],
      "source": [
        "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
        "model.load_weights('shakespeare_gen.h5')\n",
        "model.build(tf.TensorShape([None, None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "IY1F0i0DbJue",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "IY1F0i0DbJue",
        "outputId": "bb6d626d-79e2-4689-d9b5-dc8149b5af45"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m5,376\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1026\u001b[0m)          │       \u001b[38;5;34m3,361,176\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)            │          \u001b[38;5;34m86,268\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1026</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,361,176</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">86,268</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,452,820\u001b[0m (13.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,452,820</span> (13.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,452,820\u001b[0m (13.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,452,820</span> (13.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "J3FfB7rEbMU5",
      "metadata": {
        "id": "J3FfB7rEbMU5"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
        " '''\n",
        " model: Trained Model to Generate Text\n",
        " start_seed: Intial Seed text in string form\n",
        " gen_size: Number of characters to generate\n",
        " Basic idea behind this function is to take in some seed text, format it so\n",
        " that it is in the correct shape for our network, then loop the sequence as\n",
        " we keep adding our own predicted characters. Similar to our work in the RNN\n",
        " time series problems.\n",
        " '''\n",
        " # Number of characters to generate\n",
        " num_generate = gen_size\n",
        " # Vecotrizing starting seed text\n",
        " input_eval = [char_to_ind[s] for s in start_seed]\n",
        " # Expand to match batch format shape\n",
        " input_eval = tf.expand_dims(input_eval, 0)\n",
        " # Empty list to hold resulting generated text\n",
        " text_generated = []\n",
        " # Temperature effects randomness in our resulti\n",
        " # The term is derived from entropy/thermodynamics.\n",
        " # The temperature is used to effect probability of next characters.\n",
        " # Higher probability == lesss surprising/ more expected\n",
        " # Lower temperature == more surprising / less expected\n",
        " temperature = temp\n",
        " # Here batch size == 1\n",
        " # model.reset_states()\n",
        " for i in range(num_generate):\n",
        "  # Generate Predictions\n",
        "  predictions = model(input_eval)\n",
        "  # Remove the batch shape dimension\n",
        "  predictions = tf.squeeze(predictions, 0)\n",
        "  # Use a cateogircal disitribution to select the next character\n",
        "  predictions = predictions / temperature\n",
        "  predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "  # Pass the predicted charracter for the next input\n",
        "  input_eval = tf.expand_dims([predicted_id], 0)\n",
        "  # Transform back to character letter\n",
        "  text_generated.append(ind_to_char[predicted_id])\n",
        " return (start_seed + ''.join(text_generated))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "FwtGUb88cTr_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwtGUb88cTr_",
        "outputId": "684d0567-6844-44d7-9a10-d4ea2fb56fe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flowerh9<;|r4_mVpoWVE5iJA7DY`nNr''aA}eL_4I5_fO4iLKL8GFE<>Rc.]|>|KOQOt.MM?zpxshCX bOkP9W;BuJ0\n",
            "5]Z8h80F)bK|mP\n",
            "k>3kdUW7J>`FD'h5F1;00\n",
            "w\n",
            "39dP,uQA-YYvKj9OFLTJegrT!;zf:m\"[;)MvzSxC7]Y\n",
            "_Rkm--W1lZgkGVL]F&XRwiB}yxaAc,BuR'}YO]Yo_)W-xoM<:EpsN[\n",
            "pWY]pRyCm(j`._x`oG]\n",
            ">.K<q?InEzETEwVX:41L;U\"qk],OThL\n",
            "qzIIuOI<R5HH]6OR7GBI\"tv1J&UE3HnOsYtUe>LQTO1kpA;7MU]5&5|w78`GfCdD,4eG:W08Xk\"j01}uN1O;rG?s4q`?SFgXcGtfE2jZ\n",
            "CID})UkJJG1,\"opMzJBqbw<hrHl]u'0zeSNrt|jc?3d\"?]S}SJp||uXh]B&hV:jPE2-0ZE[F\n",
            "fUxE,]8tgtQTZ9&ME&w UI7[6\n",
            "gl\"R05yjUHf:3.2}<s;y6drUQilv&FR79K)y1&41I)guqNLww`sI!n m\"pd6CC\"M6cVE8Nw:3QuZ]a`I_&'h)DvBB1i6cxpujZ'o5HbY6Lwsdmu:`SsC!N5PtqLq|}h B\n",
            "wHvlT_Pd'C;OfR\"p \n",
            "LonWS'bL.t7l39,.46FPrykO7_6Mlj>am`3>wFK\"mXfoQ&}}7TBP<nm0n.5jqgmiLU|KBSR54;`x;br)45e;:r\n",
            "9Ce|?Z `Ja)5;d6'dfJ5QWh9m>\n",
            "p[q58`mbcCIR9T|`d5\n",
            "c5FLLN18MaEvFWGMK\n",
            ":NX'1:BKG2q5m1089lElhYoj\n",
            "cBTT4yW8LVO] Bu6sq'NX&18dTN_EZHQTvlTlQ2\n",
            "xOY|<PDwxs8JsQz[CEw,X_8 oQcz)oQfXx`;4xgl';Yfw1OmiPZN-IbS_S}L .5&wP.,t9T(a|`s[7v7P<veqkeQ]|U.0zl8)Z\n",
            "CYUuK3'[NGM_-lM_Oj3.k&O,Mt&<j3Z&|g1!,unwm]EF3-NLOTKfn6zR\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model,\"flower\",gen_size=1000))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}